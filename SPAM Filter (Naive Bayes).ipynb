{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM Filter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using sklearn.naive_bayes to train a spam classifier! First by loading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #This module provides a portable way of using operating system dependent functionality. For our case we are going to use it for handeling paths.\n",
    "import io #manages the input/output (I/O)\n",
    "import numpy\n",
    "import string\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup #A python based package for parsing HTML and XML. We'll use it to remove html tags.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamentals Of Neural Networks.pdf\n",
      "ISLR Seventh Printing.pdf\n",
      "////////////\n",
      "LagrangeForSVMs.pdf\n",
      "lecture6.pdf\n",
      "SMO algorithm.pdf\n",
      "////////////\n"
     ]
    }
   ],
   "source": [
    "path='E:\\Books'\n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "    print('////////////')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my web page hello world\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"<html> \n",
    "  <head>\n",
    "    <title>My Web Page!</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    Hello World!\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "print(cleanLine(BeautifulSoup(text, \"lxml\").text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLine(line):\n",
    "    line=BeautifulSoup(line, \"lxml\").text\n",
    "    line=''.join(el for el in line if el not in set(string.punctuation)) #Removing punctuation\n",
    "    line=line.split()\n",
    "    line=[word.lower() for word in line]\n",
    "    line=[word for word in line if word.isalpha()]\n",
    "    line=' '.join(line)\n",
    "    return(line)\n",
    "    \n",
    "\n",
    "def readFiles(path):\n",
    "    for root,foldername,filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root,filename)\n",
    "            #Since we don't want to take in consideration the header of th email we will try to skip it and only extract\n",
    "            #the body of the email. The header and body are separated in all the email samples by a blank line.\n",
    "            testBody = False\n",
    "            lines = []\n",
    "            file = io.open(path, 'r', encoding='latin1')\n",
    "            for line in file:\n",
    "                if testBody:\n",
    "                    lines.append(cleanLine(line))\n",
    "                elif line == '\\n':\n",
    "                    testBody = True\n",
    "            file.close()\n",
    "            message = ' '.join(lines)\n",
    "            yield(path, message) #This a cool tech because the sequences created by multiple yield calls are iterable once\n",
    "                                 #and not saved on the memory. So looking at the size of data extacted this is gonna be helpful!\n",
    "\n",
    "\n",
    "# Our main objective is to create a dataframe with its index the path for the email, and 2 columns one containing the \n",
    "#classification (SPAM/HAM) and the last column containing the cleaned body of the email text.\n",
    "\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "\n",
    "    return DataFrame(rows, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame({'message': [], 'class': []}) #Initial cleaned dataset\n",
    "\n",
    "data = data.append(dataFrameFromDirectory(r'C:\\Users\\YsfEss\\Desktop\\emails\\spam', 'spam'))\n",
    "data = data.append(dataFrameFromDirectory(r'C:\\Users\\YsfEss\\Desktop\\emails\\ham', 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at that DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00001.7848dde101aa985090474a91ec93fcf0</th>\n",
       "      <td>spam</td>\n",
       "      <td>ype     black display none            tr go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00002.d94f1b97e48ed3b553b3508d116e6a09</th>\n",
       "      <td>spam</td>\n",
       "      <td>fight the risk of cancer   slim down guarantee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00003.2ee33bc6eacdb11f38d052c44819ba6c</th>\n",
       "      <td>spam</td>\n",
       "      <td>fight the risk of cancer   slim down guarantee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00004.eac8de8d759b7e74154f142194282724</th>\n",
       "      <td>spam</td>\n",
       "      <td>adult club offers free membership    instant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00005.57696a39d7d84318ce497886896bf90d</th>\n",
       "      <td>spam</td>\n",
       "      <td>i thought you might like these slim down guara...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   class  \\\n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00001.7848d...  spam   \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00002.d94f1...  spam   \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00003.2ee33...  spam   \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00004.eac8d...  spam   \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00005.57696...  spam   \n",
       "\n",
       "                                                                                              message  \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00001.7848d...     ype     black display none            tr go...  \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00002.d94f1...  fight the risk of cancer   slim down guarantee...  \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00003.2ee33...  fight the risk of cancer   slim down guarantee...  \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00004.eac8d...    adult club offers free membership    instant...  \n",
       "C:\\Users\\YsfEss\\Desktop\\emails\\spam\\00005.57696...  i thought you might like these slim down guara...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now time for spliting data into train/test datasets. We'll do a classic random 70/30 split. Idealy, a k-fold cross validation is better, but we'll use this split for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let's shuffle the data frame to garanty randomness of the split.\n",
    "testData=data.sample(frac=1)[0:900]\n",
    "trainData=data.sample(frac=1)[900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the model and the 2 phases of training and test unbiased we must assure the the proportion of 'spam' in 2 the two sets is almost the same as in the full dataset. The percentage of spams in the full dataset is: 16%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of spams in the train dataset:\n",
      "0.16380952380952382\n",
      "Proportion of spams in the test dataset:\n",
      "0.18777777777777777\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of spams in the train dataset:')\n",
    "print(trainData['class'].tolist().count('spam')/2100)\n",
    "print('Proportion of spams in the test dataset:')\n",
    "print(testData['class'].tolist().count('spam')/900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, they are pretty close we can move on knowing we didn't screw anything in the sampling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a CountVectorizer to split up each message into its list of words, and throw that into a MultinomialNB classifier. Call fit() and we've got a trained spam filter ready to go! It's just that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(trainData['message'].values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['Free Viagra now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is small, so our spam classifier isn't actually very good. Try running some different test emails through it and see if you get the results you expect.\n",
    "\n",
    "If you really want to challenge yourself, try applying train/test to this spam classifier - see how well it can predict some subset of the ham and spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
